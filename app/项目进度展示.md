# 远程会话管理平台 - 安卓客户端设计方案

## 一、架构设计

### 1. 技术栈选择
- 开发语言：Kotlin
- 网络通信：OkHttp + WebSocket
- UI框架：Jetpack Compose
- 数据存储：Room + DataStore
- 图像处理：CameraX + MediaProjection API

### 2. 模块划分

#### 2.1 核心模块（Core）
- 网络通信管理
  * WebSocket连接管理
  * 心跳检测机制
  * 断线重连处理
- 会话管理
  * SSH/SFTP会话
  * VNC/RDP会话
  * 会话状态同步
- 权限管理
  * 运行时权限处理
  * 安全认证管理
- 数据存储
  * 连接配置存储
  * 会话状态持久化
  * 密码安全存储

#### 2.2 功能模块（Features）
- SSH终端模块
  * 终端仿真实现
  * 键盘映射处理
  * 命令历史记录
- 文件管理模块
  * SFTP协议实现
  * 文件传输管理
  * 进度监控和断点续传
- 屏幕控制模块
  * VNC客户端实现
  * RDP客户端适配
  * 触控手势支持
- 系统信息模块
  * 设备状态监控
  * 网络状态检测
  * 性能数据采集

#### 2.3 UI模块（UI）
- 主界面
  * 连接列表管理
  * 快速操作面板
  * 状态信息展示
- 终端界面
  * 自定义键盘布局
  * 终端显示优化
  * 手势操作支持
- 文件管理界面
  * 文件列表视图
  * 传输进度展示
  * 操作菜单定制
- 设置界面
  * 通用配置管理
  * 安全选项设置
  * 主题定制

## 二、功能实现

### 1. SSH终端实现
```kotlin
class SSHService {
    private val socket = WebSocket(...)
    
    fun connect(host: String, port: Int, username: String, password: String) {
        socket.emit("ssh_connect", JSONObject().apply {
            put("host", host)
            put("port", port)
            put("username", username)
            put("password", password)
        })
    }
    
    fun sendCommand(command: String) {
        socket.emit("ssh_data", command)
    }
}
```

### 2. 屏幕控制实现
```kotlin
class ScreenCaptureService : Service() {
    private lateinit var mediaProjection: MediaProjection
    private lateinit var virtualDisplay: VirtualDisplay
    
    fun startCapture() {
        // 使用MediaProjection API捕获屏幕
        val metrics = DisplayMetrics()
        windowManager.defaultDisplay.getMetrics(metrics)
        
        mediaProjection.createVirtualDisplay(
            "ScreenCapture",
            metrics.widthPixels,
            metrics.heightPixels,
            metrics.densityDpi,
            DisplayManager.VIRTUAL_DISPLAY_FLAG_AUTO_MIRROR,
            imageReader.surface,
            null,
            null
        )
    }
    
    fun processFrame(image: Image) {
        // 处理捕获的屏幕帧
        val plane = image.planes[0]
        val buffer = plane.buffer
        val pixelStride = plane.pixelStride
        val rowStride = plane.rowStride
        val rowPadding = rowStride - pixelStride * metrics.widthPixels
        
        // 转换为Bitmap并通过WebSocket发送
        // ...
    }
}
```

### 3. 文件传输实现
```kotlin
class SFTPService {
    private val chunkSize = 8192
    
    fun uploadFile(localPath: String, remotePath: String) {
        val file = File(localPath)
        val totalChunks = (file.length() + chunkSize - 1) / chunkSize
        
        file.inputStream().use { input ->
            var chunkIndex = 0
            while (chunkIndex < totalChunks) {
                val buffer = ByteArray(chunkSize)
                val bytesRead = input.read(buffer)
                if (bytesRead <= 0) break
                
                socket.emit("sftp_upload", JSONObject().apply {
                    put("path", remotePath)
                    put("chunk_index", chunkIndex)
                    put("data", Base64.encode(buffer.copyOf(bytesRead)))
                    put("total_chunks", totalChunks)
                })
                
                chunkIndex++
            }
        }
    }
}
```

## 三、性能优化

### 1. 终端优化
- 使用自定义View实现终端显示
- 实现终端输出缓冲
- 优化字符渲染性能

### 2. 文件传输优化
- 实现断点续传
- 文件分片上传
- 传输队列管理

### 3. 屏幕控制优化
- 帧率自适应
- 图像压缩处理
- 带宽占用优化

## 四、用户界面设计

### 1. 主界面
- 底部导航栏（SSH终端、文件管理、屏幕控制、设置）
- 快速连接卡片
- 最近连接历史
- 系统状态监控

### 2. 终端界面
- 自定义键盘布局（常用按键快捷访问）
- 终端设置（字体大小、配色方案）
- 手势控制（滑动切换会话）

### 3. 文件管理界面
- 文件列表视图
- 文件操作菜单
- 传输进度显示
- 搜索功能

## 五、安全性设计

### 1. 数据安全
- 密码加密存储
- 会话数据安全
- 传输加密

### 2. 权限管理
- 运行时权限请求
- 屏幕录制权限
- 存储权限

## 六、性能优化

### 1. 网络优化
- WebSocket心跳检测
- 断线重连机制
- 数据压缩传输

### 2. 内存优化
- 图像数据复用
- 大文件分块处理
- 内存缓存管理

## 七、开发计划

### 第一阶段（2周）：基础框架
1. 项目框架搭建
2. 网络通信模块
3. 基础UI组件

### 第二阶段（2周）：核心功能
1. SSH终端实现
2. 文件管理功能
3. 屏幕控制基础功能

### 第三阶段（2周）：功能完善
1. 性能优化
2. UI/UX改进
3. Bug修复和测试

## 八、风险评估

### 1. 技术风险
- 屏幕控制延迟
- 大文件传输稳定性
- 设备兼容性

### 2. 解决方案
- 优化图像压缩算法
- 实现断点续传
- 广泛的设备测试

























最大的改进是增加连接码机制，实现客户端通过连接码识别对应用户

注册登录的用户可以记录对应的客户端，再次登录使用即可，可以持久化记录客户端设备和操作记录

游客登录可以使用所有功能，除去漏洞扫描功能，注销后客户端自动下线，日志记录12小时后自动删除

增加实时屏幕功能，可以操作客户端屏幕内容，增加安卓客户端，但安卓客户端功能不全

漏洞扫描，选择客户端可以将fscan发送到对应目标对目标进行扫描

数据库功能暂时完善

 修复客户端重复记录问题：仅在收到 device_fingerprint 时才创建或查找数据库记录，避免生成不完整记录

移除临时连接 ID（如 7、8 等）入库逻辑；创建新记录不再使用临时 ID

优化断开连接的离线标记：优先使用连接期映射的数据库主键（db_client_id），避免误更新

SQLite特点：

- 文件型数据库 ：SQLite是一个文件型数据库，整个数据库就是一个文件，不需要服务器进程
- 轻量级 ：体积小，占用资源少，适合嵌入式设备和移动应用
- 零配置 ：不需要安装和配置，使用非常简单
- 自包含 ：不依赖外部服务，应用程序可以直接读写数据库文件
- 单用户 ：主要设计用于单用户访问，并发性能有限








下面是对“屏幕实时监控与操控”在你这套代码中的端到端实现逻辑的详细梳理与解释。我将从数据流、关键文件、事件与指令格式、图像流与输入控制两大通道、以及多显示器与缩放处理等角度逐层说明。

一、核心文件与职责概览
- 前端页面与交互：
  - <mcfile name="remote_control.html" path="e:\test\app\templates\dashboard\remote_control.html"></mcfile>
    - 浏览器端 Socket.IO 客户端：连接后自动下发 start_screen 命令，请求客户端推流；监听页面关闭发送 stop_screen。
    - 监听 screen_frame_update 事件：收到服务器转发的屏幕帧后更新 <img> src（data:image/jpeg;base64,...）。
    - 采集鼠标、键盘事件；对鼠标进行坐标映射到被控端“虚拟屏幕”绝对坐标；通过 send_command 发送 mouse/key 指令。
- Web 服务端（Socket.IO 接入层）：
  - <mcfile name="sockets.py" path="e:\test\app\web\sockets.py"></mcfile>
    - 事件 send_command：接收来自网页的控制命令，转投到 client_manager.client_queues[client_id] 队列。
    - 其它与实时流相关：new_screenshot 处理（与图库/截图功能有关），clients 列表等。
- TCP 服务端（客户端接入层，转发与推流中转）：
  - <mcfile name="tcp_server.py" path="e:\test\app\connect_func\tcp_server.py"></mcfile>
    - send_thread：从 client_manager.client_queues[client_id] 取出命令，reliable_send 通过 TCP 发给对应客户端。
    - receive_thread：从客户端收 JSON 行协议数据；当 type == 'screen_frame' 时，socketio.emit('screen_frame_update', ...) 转发给网页。
- 客户端（Windows 端被控程序）：
  - <mcfile name="client.py" path="e:\test\app\客户端\client.py"></mcfile>
    - handle_start_screen/handle_stop_screen：管理屏幕抓取线程与停止事件。
    - _screen_stream_loop：循环抓屏 → 可选缩放 → JPEG 编码 → Base64 → 通过 TCP reliable_send 发送 type='screen_frame' 帧和元数据(w,h,vx,vy,vw,vh)。
    - handle_mouse/handle_key：解析 mouse/key 指令，调用 Win32 API 或 ctypes 进行输入注入（移动、按压、滚轮、键盘上下/点击等）。

二、端到端时序（数据与控制流）
- 浏览器 → Web（Socket.IO）：
  - 页面加载并连接 Socket.IO 后，立即发送 send_command:
    - target: clientId
    - command: { action: 'start_screen', arg: 'fps=15,quality=50,width=1024' }
  - 用户在页面上对图像进行鼠标/键盘操作时，前端将这些事件转换为 send_command 的 mouse/key 指令。
- Web（Socket.IO）→ TCP 服务端 → 客户端：
  - Web 层的 send_command 处理器把指令放入 client_manager.client_queues[client_id] 队列。
  - TCP 层的 send_thread 消费队列，reliable_send 通过该客户端的 TCP 连接把命令（JSON 行）发送给客户端。
- 客户端执行与回传：
  - 客户端收到 start_screen 后，启动 _screen_stream_loop，用设定的 fps/quality/width 抓屏、压缩、发送。
  - 客户端收到 mouse/key 指令，调用 OS API 执行鼠标移动/点击/滚轮或键盘按压/释放。
- 客户端 → TCP 服务端 → Web（Socket.IO）→ 浏览器：
  - 客户端持续发送 type='screen_frame' 的 JSON（含帧图 base64 与屏幕元数据），TCP receive_thread 收到后 socketio.emit('screen_frame_update', {...})。
  - 浏览器端监听 screen_frame_update，匹配 client_id 后更新 img 的 src，实现“实时监控”。

三、实时监控（图像流）实现要点
- 前端发起推流：
  - <mcfile name="remote_control.html" path="e:\test\app\templates\dashboard\remote_control.html"></mcfile> 页面连接 Socket.IO 后，自动 emit 'send_command'，action='start_screen'，参数 arg 包含 fps、quality、width，作为客户端抓屏线程的配置。
  - 页面 unload 前 emit 'stop_screen'，以便资源释放。
- 客户端抓屏与编码：
  - <mcfile name="client.py" path="e:\test\app\客户端\client.py"></mcfile> 中 _screen_stream_loop：
    - take_screenshot() 获取当前屏幕图像（Windows 下首选 pywin32，回退 Pillow），记录原始尺寸 orig_w,orig_h。
    - 若设置了 max_width（width），按比例缩放以降低带宽。
    - 记录 frame_w, frame_h；读取“虚拟屏幕”参数 vx,vy,vw,vh（多显示器情况下，Windows 的虚拟屏覆盖所有显示器坐标范围）。
    - 将图像转 JPEG（quality），再 base64 编码。
    - reliable_send 发送 JSON：{type:'screen_frame', data: base64_jpeg, w,h,vx,vy,vw,vh}。
    - 通过线程停止事件与 fps 间隔控制速率（interval=1/fps）。
- 服务器转发到浏览器：
  - <mcfile name="tcp_server.py" path="e:\test\app\connect_func\tcp_server.py"></mcfile> 的 receive_thread 中，当 data['type']=='screen_frame'：
    - socketio.emit('screen_frame_update', { client_id, data, w,h,vx,vy,vw,vh })
    - 注意：这里未限定房间，等同广播（你的前端再按 client_id 过滤）。
- 浏览器渲染与 FPS 指示：
  - <mcfile name="remote_control.html" path="e:\test\app\templates\dashboard\remote_control.html"></mcfile> 中:
    - 监听 screen_frame_update 后，将 <img id="screen-viewer"> 的 src 设为 data:image/jpeg;base64,xxx。
    - 依据帧到达频率统计并显示近似 FPS。

四、实时操控（鼠标/键盘）实现要点
- 坐标映射（关键）：
  - 前端的 img 使用 object-fit:contain；实际显示尺寸可能小于容器并有留边。代码通过 getImageContentBox 计算图片内容区的实际显示框（displayW/displayH 与 offset）。
  - 将鼠标事件的 clientX/clientY 映射到图片内容区的归一化坐标 px/py，再映射到虚拟屏绝对坐标：
    - absX = vx + px * vw
    - absY = vy + py * vh
  - lastMeta 由最近 screen_frame_update 帧更新，包含 w,h,vx,vy,vw,vh，使映射适配多显示器与不同缩放。
- 鼠标事件处理：
  - mousedown/mouseup：先发送 move 到当前映射坐标，再发送 down/up 指定按键（left/right/middle）。
  - mousemove：节流处理（~16ms 不按下时），降低网络压测；每次移动发送 move x y。
  - wheel：将浏览器 deltaY 归一为 ±120 的整数倍（与 Windows WHEEL_DELTA 对齐）。
  - 这些事件统一通过 socket.emit('send_command', { target, command: {action:'mouse', arg:'...' }}) 发往服务器。
- 键盘事件处理：
  - keydown/keyup：把 e.key 规范化（空格 -> 'Space'），发送 'key down KEY' / 'key up KEY'。
  - 客户端端侧 <mcfile name="client.py" path="e:\test\app\客户端\client.py"></mcfile> 的 handle_key：
    - _key_to_vk 将 'Enter'、'Escape'、字母/数字、以及 'VK_RETURN' 这类 VK_* 前缀做映射到虚拟键值。
    - 调用 win32api.keybd_event（或 ctypes 回退）执行按下/抬起/press。
- 服务器命令转发：
  - <mcfile name="sockets.py" path="e:\test\app\web\sockets.py"></mcfile> 的 send_command：
    - 从前端收到 {target, command:{action,arg}}。
    - 放入 client_manager.client_queues[cid]。
  - <mcfile name="tcp_server.py" path="e:\test\app\connect_func\tcp_server.py"></mcfile> 的 send_thread：
    - 从队列获取命令 JSON，reliable_send 到该客户端 TCP 连接。
  - 客户端主循环解析 action，将 'mouse'、'key' 分派给 handle_mouse/handle_key 执行。

五、命令与事件的格式（关键字段）
- 前端 → Web（Socket.IO）send_command 数据结构：
  - { target: clientId, command: { action: 'start_screen'|'stop_screen'|'mouse'|'key'|..., arg: '...' } }
- Web → 客户端（TCP）JSON 行协议：
  - {"action":"start_screen","arg":"fps=15,quality=50,width=1024"}
  - {"action":"mouse","arg":"move 123 456"}、{"action":"mouse","arg":"down left"} 等
  - {"action":"key","arg":"down A"}、{"action":"key","arg":"up Enter"} 等
- 客户端 → Web（通过 TCP→Socket.IO 转发）：
  - {"type":"screen_frame","data": base64_jpeg, "w": frame_w, "h": frame_h, "vx":..., "vy":..., "vw":..., "vh":...}
  - Web 转发事件名：screen_frame_update，前端按 client_id 过滤显示。

六、多显示器与缩放处理
- 多显示器：客户端通过 Windows 虚拟屏指标 SM_X/Y/CX/CYVIRTUALSCREEN 获取 vx,vy,vw,vh，表示“虚拟屏幕”左上角与宽高（包括所有显示器合并的逻辑坐标系）。
- 前端缩放与留边：因为 <img> 是等比缩放 contain，必须计算内容区显示框，才能把鼠标事件从“网页显示坐标”正确映射回“虚拟屏幕绝对坐标”。
- 帧缩放：客户端依据 width 参数对截图帧缩小，降低编码与传输开销；前端只用于显示，不需知道原图尺寸，只要用同帧的 w,h 与虚拟屏指标进行映射即可。

七、资源释放与会话结束
- 浏览器 beforeunload 主动发送 stop_screen，客户端停止 _screen_stream_loop 并回收线程。
- 客户端侧 _screen_stop_event 控制线程退出，避免僵尸线程与资源泄露。

八、与 VNC/RDP 的关系区分
- 该“自研截图 + 控制”链路与 VNC/RDP 是并列存在的功能：
  - VNC：前端 noVNC 客户端，详见 <mcfile name="vnc 目录" path="e:\test\app\static\novnc\"></mcfile> 以及 vnc_view.html；走 RFB/WebSocket，不走上面这套 screen_frame。
  - RDP：前端 iframe 嵌入 guac_url，见 rdp_view.html；通过后端服务桥接。
- 本回答聚焦的“remote_control.html + sockets.py + tcp_server.py + client.py”是定制的“截图帧 + 输入注入”方案。

九、可观测现象与参数调优建议
- 你可以在浏览器里看到状态文本显示的 FPS；帧率会受网络与编码影响。
- 可以调节 start_screen 的 fps、quality、width 三个参数，折中清晰度与流畅度、带宽占用。
- 鼠标移动已做 16ms 节流；如果网络较差，建议进一步降低发包频率或在服务器端做合并/丢弃策略。
- 如需更丝滑：可以考虑后续加入增量编码（非必须）、HEIF/AVIF/H.264 等视频/帧缓存方案；当前为 JPEG 单帧流更简单直观。

十、小结（端到端一图流）
- 浏览器(remote_control.html)：连接后发 start_screen → 收 screen_frame_update → 绘制图片；采集鼠标/键盘 → 发 mouse/key。
- Web(sockets.py)：接收 send_command → 投递到 client_queues；收到 TCP 转发的 screen_frame → emit 给前端。
- TCP 服务端(tcp_server.py)：send_thread 消费队列发给某客户端；receive_thread 收客户端帧并转发到 Web。
- 客户端(client.py)：start_screen 启动抓屏线程，循环抓图编码发送；handle_mouse/handle_key 注入输入事件到系统。

如果你希望，我可以再把某一段的关键代码路径、参数约定或异常处理策略拆得更细，或者根据你的网络/负载情况，给出简易的参数配置建议。
        